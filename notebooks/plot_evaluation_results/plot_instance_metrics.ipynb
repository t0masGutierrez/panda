{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display config\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metric_lists(metrics_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse list-valued metric columns that were serialized as strings.\"\"\"\n",
    "\n",
    "    def parse_value(value: Any) -> Any:\n",
    "        if isinstance(value, str):\n",
    "            stripped = value.strip()\n",
    "            if stripped.startswith(\"[\") and stripped.endswith(\"]\"):\n",
    "                inner = stripped[1:-1].strip()\n",
    "                if not inner:\n",
    "                    return []\n",
    "                parsed_vals: list[float] = []\n",
    "                for token in inner.split(\",\"):\n",
    "                    component = token.strip()\n",
    "                    if not component:\n",
    "                        continue\n",
    "                    lowered = component.lower()\n",
    "                    if lowered == \"nan\":\n",
    "                        parsed_vals.append(np.nan)\n",
    "                    elif lowered in {\"inf\", \"+inf\"}:\n",
    "                        parsed_vals.append(np.inf)\n",
    "                    elif lowered == \"-inf\":\n",
    "                        parsed_vals.append(-np.inf)\n",
    "                    else:\n",
    "                        parsed_vals.append(float(component))\n",
    "                return parsed_vals\n",
    "        return value\n",
    "\n",
    "    parsed = metrics_df.copy()\n",
    "    for column in parsed.columns:\n",
    "        if column == \"system\":\n",
    "            continue\n",
    "        parsed[column] = parsed[column].apply(parse_value)\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def aggregate_system_metrics(metrics_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Collapse per-instance lists into per-system aggregates.\"\"\"\n",
    "\n",
    "    def aggregate_value(value: Any) -> Any:\n",
    "        if isinstance(value, list):\n",
    "            arr = np.asarray(value, dtype=float)\n",
    "            if arr.size == 0:\n",
    "                return np.nan\n",
    "            return float(np.nanmean(arr))\n",
    "        return value\n",
    "\n",
    "    aggregated = metrics_df.copy()\n",
    "    for column in aggregated.columns:\n",
    "        if column == \"system\":\n",
    "            continue\n",
    "        aggregated[column] = aggregated[column].apply(aggregate_value)\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def list_system_names(system_dir: Path) -> list[str]:\n",
    "    \"\"\"Return sorted system names discovered in the provided directory.\"\"\"\n",
    "    if not system_dir.exists():\n",
    "        raise FileNotFoundError(f\"System directory not found: {system_dir}\")\n",
    "    return sorted(child.name for child in system_dir.iterdir() if child.is_dir())\n",
    "\n",
    "\n",
    "def load_lyapunov_map(\n",
    "    json_path: Path,\n",
    "    bucket_key: str | int | None = \"4096\",\n",
    "    metric_key: str = \"max_lyap_rosenstein\",\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Load average Lyapunov exponents per system from JSON.\"\"\"\n",
    "    with json_path.open() as fh:\n",
    "        data = json.load(fh)\n",
    "    if bucket_key is None:\n",
    "        key = next(iter(data))\n",
    "        entries = data[key]\n",
    "    else:\n",
    "        entries = data[str(bucket_key)]\n",
    "\n",
    "    lyap_values: dict[str, list[float]] = defaultdict(list)\n",
    "    for system_name, metrics in entries:\n",
    "        value = metrics.get(metric_key)\n",
    "        if value is None:\n",
    "            continue\n",
    "        lyap_values[system_name].append(float(value))\n",
    "\n",
    "    return {system: float(np.nanmean(values)) for system, values in lyap_values.items()}\n",
    "\n",
    "\n",
    "def load_metrics_for_model(\n",
    "    model_name: str, metrics_dir: Path\n",
    ") -> tuple[dict[int, dict[str, list[float]]], dict[int, pd.DataFrame]]:\n",
    "    \"\"\"Load CSV metrics for a single model, returning aggregated and per-instance registries.\"\"\"\n",
    "    aggregated_registry: dict[int, dict[str, list[float]]] = {}\n",
    "    instance_registry: dict[int, pd.DataFrame] = {}\n",
    "\n",
    "    csv_paths = sorted(\n",
    "        [path for path in metrics_dir.glob(\"*.csv\")],\n",
    "        key=lambda path: int(path.stem.split(\"_pred\")[1]),\n",
    "    )\n",
    "    if not csv_paths:\n",
    "        raise FileNotFoundError(f\"No CSV metrics found in {metrics_dir}\")\n",
    "\n",
    "    for csv_path in csv_paths:\n",
    "        prediction_length = int(csv_path.stem.split(\"_pred\")[1])\n",
    "        metrics_df = pd.read_csv(csv_path)\n",
    "        parsed_metrics = parse_metric_lists(metrics_df)\n",
    "        aggregated_metrics = aggregate_system_metrics(parsed_metrics)\n",
    "        aggregated_registry[prediction_length] = aggregated_metrics.to_dict()\n",
    "        instance_registry[prediction_length] = parsed_metrics\n",
    "\n",
    "    return aggregated_registry, instance_registry\n",
    "\n",
    "\n",
    "def build_instance_metric_dataframe(\n",
    "    model_name: str,\n",
    "    prediction_length: int,\n",
    "    metric_name: str,\n",
    "    instance_registry: dict[str, dict[int, pd.DataFrame]],\n",
    "    systems: list[str] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Explode per-instance metrics for a specific model/prediction length.\"\"\"\n",
    "    if model_name not in instance_registry:\n",
    "        raise KeyError(f\"Model '{model_name}' not found in instance registry\")\n",
    "    model_metrics = instance_registry[model_name]\n",
    "    if prediction_length not in model_metrics:\n",
    "        raise KeyError(f\"Prediction length {prediction_length} missing for model '{model_name}'\")\n",
    "\n",
    "    df = model_metrics[prediction_length]\n",
    "    if metric_name not in df.columns:\n",
    "        raise KeyError(f\"Metric '{metric_name}' not available for model '{model_name}'\")\n",
    "    if systems is not None:\n",
    "        df = df[df[\"system\"].isin(systems)]\n",
    "\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        values = getattr(row, metric_name)\n",
    "        if isinstance(values, np.ndarray):\n",
    "            instance_values = values.tolist()\n",
    "        elif isinstance(values, list):\n",
    "            instance_values = values\n",
    "        else:\n",
    "            instance_values = [values]\n",
    "        for instance_idx, value in enumerate(instance_values):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"model\": model_name,\n",
    "                    \"system\": row.system,\n",
    "                    \"prediction_length\": prediction_length,\n",
    "                    \"metric\": metric_name,\n",
    "                    \"instance_index\": instance_idx,\n",
    "                    \"value\": value,\n",
    "                    \"system_dims\": getattr(row, \"system_dims\", np.nan),\n",
    "                    \"n_system_samples\": getattr(row, \"n_system_samples\", np.nan),\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def compute_system_metric_summary(instance_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute summary statistics per system for the metric values.\"\"\"\n",
    "    summary = instance_df.groupby(\"system\")[\"value\"].agg(median=\"median\", mean=\"mean\", std=\"std\", count=\"count\")\n",
    "    summary[\"sem\"] = summary[\"std\"] / np.sqrt(summary[\"count\"])\n",
    "    return summary\n",
    "\n",
    "\n",
    "def plot_system_metric_distributions(\n",
    "    instance_df: pd.DataFrame,\n",
    "    metric_name: str,\n",
    "    prediction_length: int,\n",
    "    model_name: str,\n",
    "    lyapunov_map: dict[str, float] | None = None,\n",
    "    output_path: Path | None = None,\n",
    "    figsize: tuple[float, float] = (20, 6),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create a per-system boxplot and optionally overlay Lyapunov exponents.\n",
    "\n",
    "    Displays inline if output_path is None; otherwise saves to the provided path.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    if lyapunov_map is not None:\n",
    "        systems = instance_df.system.unique()\n",
    "        order = sorted(systems, key=lyapunov_map.__getitem__)\n",
    "    else:\n",
    "        medians = instance_df.groupby(\"system\")[\"value\"].median().sort_values()\n",
    "        order = medians.index.tolist()\n",
    "\n",
    "    df = instance_df.copy()\n",
    "    df[\"system\"] = pd.Categorical(df[\"system\"], categories=order, ordered=True)\n",
    "    df = df.sort_values(\"system\")\n",
    "    df.boxplot(column=\"value\", by=\"system\", ax=ax, rot=45, widths=0.8)\n",
    "    ax.grid(False)\n",
    "\n",
    "    if lyapunov_map is not None:\n",
    "        ax2 = ax.twinx()\n",
    "        lyaps = [lyapunov_map.get(sys, 0.0) for sys in systems]\n",
    "        ax2.plot(range(1, len(systems) + 1), lyaps, \"ro:\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if output_path is not None:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(output_path, bbox_inches=\"tight\")\n",
    "        print(f\"Saved plot to {output_path}\")\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path(os.getenv(\"WORK\", \"/stor/work/Gilpin\"))\n",
    "\n",
    "model_name = \"Panda\"\n",
    "metric_name = \"smape\"\n",
    "prediction_length = 64\n",
    "\n",
    "metrics_dir = work_dir / \"eval_results\" / \"patchtst\" / \"pft_chattn_emb_w_poly-0\" / \"test_zeroshot\"\n",
    "systems_dir = work_dir / \"data\" / \"improved\" / \"final_base40\" / \"test_zeroshot\"\n",
    "lyapunov_json = Path(\"../../data/max_lyap_r_test_zeroshot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load registries and system metadata\n",
    "aggregated_registry, instance_registry = load_metrics_for_model(model_name, metrics_dir)\n",
    "all_instance_metrics = {model_name: instance_registry}\n",
    "\n",
    "systems = list_system_names(systems_dir)\n",
    "lyapunov_map = load_lyapunov_map(lyapunov_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyaps = defaultdict(list)\n",
    "avg_lyaps = defaultdict(float)\n",
    "for instance_name, lyap in lyapunov_map.items():\n",
    "    system = instance_name.split(\"_\")[0]\n",
    "    lyaps[system].append(lyap)\n",
    "avg_lyaps = {sys: sum(ls) / len(ls) for sys, ls in lyaps.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_df = build_instance_metric_dataframe(\n",
    "    model_name=model_name,\n",
    "    prediction_length=prediction_length,\n",
    "    metric_name=metric_name,\n",
    "    instance_registry=all_instance_metrics,\n",
    "    systems=systems,\n",
    ")\n",
    "plot_system_metric_distributions(\n",
    "    instance_df=instance_df,\n",
    "    lyapunov_map=avg_lyaps,\n",
    "    metric_name=metric_name,\n",
    "    prediction_length=prediction_length,\n",
    "    model_name=model_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyapunov_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
