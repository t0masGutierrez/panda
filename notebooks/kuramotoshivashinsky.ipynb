{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.base import DynSys\n",
    "from dysts.metrics import compute_metrics\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from panda.chronos.pipeline import ChronosPipeline\n",
    "from panda.patchtst.pipeline import PatchTSTPipeline\n",
    "from panda.utils.data_utils import safe_standardize\n",
    "from panda.utils.plot_utils import apply_custom_style\n",
    "\n",
    "device_rank = 3\n",
    "device = torch.device(f\"cuda:{device_rank}\")\n",
    "\n",
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "def has_module(module_name: str) -> bool:\n",
    "    \"\"\"Check if a module is installed\"\"\"\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_save_dir = \"../figures/kuramoto_sivashinsky\"\n",
    "os.makedirs(figs_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.path.expandvars(\"$WORK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuramotoShivashinsky(DynSys):\n",
    "    \"\"\"Implements the 1+1D KS equation in fourier space\"\"\"\n",
    "\n",
    "    def __init__(self, L: float, modes: int):\n",
    "        self.ic = None\n",
    "        super().__init__(metadata_path=None, dimension=2 * modes, parameters={})\n",
    "        self.L = L\n",
    "        self.modes = modes\n",
    "        self.dimension = 2 * self.modes\n",
    "        self.wave_nums = 2 * np.pi * np.arange(0, self.modes + 2) / self.L\n",
    "        self.N = self.dimension + 2\n",
    "\n",
    "        # precompute some quantities\n",
    "        self.freq_domain = np.zeros(self.modes + 2, dtype=np.complex128)\n",
    "        self.nonlinear_factor = -0.5 * 1j * self.wave_nums * self.N\n",
    "        self.diffusion_ffts = self.wave_nums**2 - self.wave_nums**4\n",
    "\n",
    "    def to_spatial(self, q: np.ndarray, N: int) -> np.ndarray:\n",
    "        \"\"\"Inverse FFT of the modes to get u(x) at a certain time\n",
    "\n",
    "        :param q: array of flattened fourier coefficients (real and imag components), can have batch dimensions\n",
    "        :param N: grid resolution in the spatial domain\n",
    "\n",
    "        :returns: solution in the spatial domain\n",
    "        \"\"\"\n",
    "        coeffs = np.zeros(q.shape[:-1] + (self.modes + 2,), dtype=complex)\n",
    "        coeffs[..., 1:-1] = q[..., : self.modes] + 1j * q[..., self.modes :]\n",
    "        return np.fft.irfft(coeffs, n=N)\n",
    "\n",
    "    def rhs(self, t: float, X: np.ndarray) -> np.ndarray:\n",
    "        self.freq_domain[1:-1] = X[: self.modes] + 1j * X[self.modes :]\n",
    "        u = np.fft.irfft(self.freq_domain, n=self.N)\n",
    "        pseudospectral_term = self.nonlinear_factor * np.fft.rfft(u * u)\n",
    "        linear_term = self.diffusion_ffts * self.freq_domain\n",
    "\n",
    "        # repackage components\n",
    "        flow = (linear_term + pseudospectral_term)[1:-1]\n",
    "        return np.concatenate([np.real(flow), np.imag(flow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = KuramotoShivashinsky(L=100, modes=64)\n",
    "\n",
    "tfinal = 100\n",
    "rng = np.random.default_rng(12)  # 1234\n",
    "ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "teval = np.linspace(0, tfinal, 4096)\n",
    "sol = solve_ivp(ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8)\n",
    "ts, freq_traj = sol.t, sol.y.T\n",
    "spatial_traj = ks.to_spatial(freq_traj, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0, ks.L, ks.dimension)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.pcolormesh(ts, grid, spatial_traj.T, cmap=\"RdBu\", shading=\"gouraud\")\n",
    "plt.colorbar()\n",
    "plt.ylabel(\"x\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "run_name = \"pft_chattn_noembed_pretrained_correct-0\"\n",
    "pipeline = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"{WORK_DIR}/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    normalize: bool = True,\n",
    "    transpose: bool = False,\n",
    "    prediction_length: int | None = None,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    context = trajectory[:context_length]\n",
    "    if normalize:\n",
    "        context = safe_standardize(context, axis=0)\n",
    "\n",
    "    if prediction_length is None:\n",
    "        prediction_length = trajectory.shape[0] - context_length\n",
    "\n",
    "    if transpose:\n",
    "        context = context.T\n",
    "\n",
    "    predictions = (\n",
    "        pipeline.predict(\n",
    "            context=torch.tensor(context).float(),\n",
    "            prediction_length=prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    full_trajectory = np.concatenate([context, predictions], axis=1 if transpose else 0)\n",
    "\n",
    "    if transpose:\n",
    "        full_trajectory = full_trajectory.T\n",
    "\n",
    "    if normalize:\n",
    "        return safe_standardize(\n",
    "            full_trajectory,\n",
    "            axis=0,\n",
    "            context=trajectory[:context_length],\n",
    "            denormalize=True,\n",
    "        )\n",
    "\n",
    "    return full_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(\n",
    "    ts: np.ndarray,\n",
    "    grid: np.ndarray,\n",
    "    trajectory: np.ndarray,\n",
    "    predictions: np.ndarray,\n",
    "    run_name: str = \"\",\n",
    "    context_length: int = 512,\n",
    "    save_path: str | None = None,\n",
    "    v_abs: float | None = None,\n",
    "    prediction_horizon: int = 128,\n",
    "    cmap_name: str = \"RdBu\",\n",
    "    title_kwargs: dict = {},\n",
    "    draw_prediction_horizon_line: bool = True,\n",
    "    figsize: tuple[int, int] = (9, 9),\n",
    "    show_cbar: bool = True,\n",
    "    show_ticks: bool = True,\n",
    "    show_axes_labels: bool = True,\n",
    "    show_context: bool = True,\n",
    "):\n",
    "    fig, axes = plt.subplots(3, 1, sharex=True, figsize=figsize)\n",
    "\n",
    "    vmin = min(trajectory.min(), predictions.min())\n",
    "    vmax = max(trajectory.max(), predictions.max())\n",
    "    vabs = v_abs or max(abs(vmin), abs(vmax))\n",
    "\n",
    "    if not show_context:\n",
    "        ts = ts[context_length:]\n",
    "\n",
    "    for i, (ax, data, label) in enumerate(\n",
    "        zip(\n",
    "            axes,\n",
    "            [trajectory, predictions, predictions - trajectory],\n",
    "            [\n",
    "                \"Ground Truth\",\n",
    "                f\"Predictions ({run_name})\" if run_name else \"Predictions\",\n",
    "                \"Error\",\n",
    "                # f\"Prediction Error ({np.mean(np.abs(predictions[context_length:] - trajectory[context_length:])):.2e}) ({run_name})\",\n",
    "            ],\n",
    "        )\n",
    "    ):\n",
    "        if not show_context:\n",
    "            data = data[context_length:]\n",
    "        im = ax.pcolormesh(ts, grid, data.T, cmap=cmap_name, shading=\"gouraud\", vmin=-vabs, vmax=vabs)\n",
    "        if show_ticks:\n",
    "            ax.set_ylabel(\"x\")\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        ax.set_title(label, **title_kwargs)\n",
    "        if show_cbar:\n",
    "            fig.colorbar(im, ax=ax)\n",
    "        # draw black vertical line at middle of plot (x axis middle)\n",
    "\n",
    "        if show_context:\n",
    "            ax.axvline(ts[context_length], color=\"black\", linewidth=1)\n",
    "\n",
    "        if i == 2 and draw_prediction_horizon_line:\n",
    "            # draw a black dotted vertical line at the end of 128 pred length window\n",
    "            start = context_length if show_context else 0\n",
    "            ax.axvline(\n",
    "                ts[start + prediction_horizon],\n",
    "                color=\"gray\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "            )\n",
    "    if show_ticks:\n",
    "        axes[-1].set_xlabel(\"t\")\n",
    "        # axes[-1].set_xticks(ts[::256])\n",
    "    else:\n",
    "        for ax in axes:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    if show_axes_labels:\n",
    "        axes[-1].set_xlabel(\"Time\", fontweight=\"bold\")\n",
    "        for ax in axes:\n",
    "            ax.set_ylabel(\"x\", fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    return vabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 1024\n",
    "context_length = 512\n",
    "\n",
    "prediction_length = 256\n",
    "end_time = start_time + (context_length + prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_deterministic = True  # for Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict in frequency domain\n",
    "# preds_freq = forecast(\n",
    "#     pipeline,\n",
    "#     freq_traj[start_time:end_time],\n",
    "#     context_length,\n",
    "#     prediction_length=512,\n",
    "#     normalize=True,\n",
    "#     sliding_context=True,\n",
    "# )\n",
    "\n",
    "# # convert to spatial domain\n",
    "# preds_freq_to_spatial = ks.to_spatial(preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_freq_vabs = plot_forecast(\n",
    "#     ts[start_time:end_time],\n",
    "#     grid,\n",
    "#     spatial_traj[start_time:end_time],\n",
    "#     preds_freq_to_spatial,\n",
    "#     run_name=\"Panda\",\n",
    "#     context_length=context_length,\n",
    "#     save_path=\"../figures/ks_our_model_freq_to_spatial.pdf\",\n",
    "#     cmap_name=\"RdBu\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "preds_spatial = forecast(\n",
    "    pipeline,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    normalize=True,\n",
    "    sliding_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_spatial_vabs = plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    preds_spatial,\n",
    "    context_length=context_length,\n",
    "    save_path=os.path.join(figs_save_dir, \"ks_our_model_spatial.pdf\"),\n",
    "    cmap_name=\"RdBu\",\n",
    "    title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 8},\n",
    "    show_ticks=True,\n",
    "    show_axes_labels=True,\n",
    "    show_cbar=True,\n",
    "    figsize=(3.2, 5),\n",
    "    show_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    f\"{WORK_DIR}/checkpoints/chronos_t5_mini_ft-0/checkpoint-final\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_chronos(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    chunk_size: int,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    subchannel_predictions = []\n",
    "    for i in trange(0, trajectory.shape[1] // chunk_size, leave=False):\n",
    "        subpreds = forecast(\n",
    "            pipeline,\n",
    "            trajectory[:, i * chunk_size : (i + 1) * chunk_size],\n",
    "            context_length,\n",
    "            prediction_length=None,\n",
    "            transpose=True,\n",
    "            normalize=False,\n",
    "            num_samples=1,\n",
    "            **kwargs,\n",
    "        )\n",
    "        subchannel_predictions.append(subpreds)\n",
    "\n",
    "    return np.concatenate(subchannel_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict in frequency domain\n",
    "# chronos_preds_freq = forecast_chronos(\n",
    "#     chronos_ft, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    "# )\n",
    "\n",
    "# # convert to spatial domain\n",
    "# chronos_preds_freq_to_spatial = ks.to_spatial(chronos_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(\n",
    "#     ts[start_time:end_time],\n",
    "#     grid,\n",
    "#     spatial_traj[start_time:end_time],\n",
    "#     chronos_preds_freq_to_spatial,\n",
    "#     run_name=\"Chronos 20M SFT\",\n",
    "#     context_length=context_length,\n",
    "#     save_path=\"../figures/ks_chronos_ft_freq_to_spatial.pdf\",\n",
    "#     v_abs=our_freq_vabs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_preds_spatial = forecast_chronos(\n",
    "    chronos_ft,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    "    deterministic=use_deterministic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_preds_spatial,\n",
    "    run_name=\"Chronos 20M SFT\",\n",
    "    context_length=context_length,\n",
    "    save_path=os.path.join(figs_save_dir, \"ks_chronos_ft_spatial.pdf\"),\n",
    "    v_abs=our_spatial_vabs,\n",
    "    cmap_name=\"RdBu\",\n",
    "    title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 8},\n",
    "    show_ticks=False,\n",
    "    show_cbar=False,\n",
    "    figsize=(3, 5),\n",
    "    show_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronos_zs_preds_freq = forecast_chronos(\n",
    "#     chronos_zs, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    "# )\n",
    "\n",
    "# # convert to spatial domain\n",
    "# chronos_zs_preds_freq_to_spatial = ks.to_spatial(chronos_zs_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(\n",
    "#     ts[start_time:end_time],\n",
    "#     grid,\n",
    "#     spatial_traj[start_time:end_time],\n",
    "#     chronos_zs_preds_freq_to_spatial,\n",
    "#     run_name=\"Chronos 20M\",\n",
    "#     context_length=context_length,\n",
    "#     save_path=\"../figures/ks_chronos_zs_freq_to_spatial.pdf\",\n",
    "#     v_abs=our_freq_vabs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_zs_preds_spatial = forecast_chronos(\n",
    "    chronos_zs,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    "    deterministic=use_deterministic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_zs_preds_spatial,\n",
    "    run_name=\"Chronos 20M\",\n",
    "    context_length=context_length,\n",
    "    save_path=os.path.join(figs_save_dir, \"ks_chronos_zs_spatial.pdf\"),\n",
    "    v_abs=our_spatial_vabs,\n",
    "    cmap_name=\"RdBu\",\n",
    "    title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 8},\n",
    "    show_ticks=False,\n",
    "    show_cbar=False,\n",
    "    figsize=(3, 5),\n",
    "    show_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_module(\"neuralop\"):\n",
    "    from neuralop.models import FNO\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fno_rollout(context: np.ndarray, num_steps: int, model: torch.nn.Module, lookback: int) -> torch.Tensor:\n",
    "        stand_context = safe_standardize(context, axis=0)\n",
    "        ic = torch.tensor(stand_context[-lookback:]).float().to(device).unsqueeze(0)\n",
    "        traj = [ic]\n",
    "        state = ic.clone()\n",
    "        for _ in range(num_steps):\n",
    "            pred = model(state)\n",
    "            traj.append(pred)\n",
    "            state = torch.cat([state[:, :-1, :], pred], dim=1)\n",
    "        pred = torch.cat(traj, dim=1)[:, lookback:, :].cpu().numpy().squeeze()\n",
    "        traj = np.concatenate([stand_context, pred], axis=0)\n",
    "        return safe_standardize(traj, axis=0, context=context, denormalize=True)\n",
    "\n",
    "    lookback = 8\n",
    "    operator = FNO(n_modes=(256,), hidden_channels=256, n_layers=6, in_channels=lookback, out_channels=1).to(device)\n",
    "    operator.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"{WORK_DIR}/checkpoints/KS-baselines-full/best_model_state_dict.pt\",\n",
    "            map_location=device,\n",
    "            weights_only=False,\n",
    "        )\n",
    "    )\n",
    "    operator.eval()\n",
    "\n",
    "    fno_preds_spatial = fno_rollout(\n",
    "        spatial_traj[start_time : start_time + context_length],\n",
    "        end_time - start_time - context_length,\n",
    "        operator,\n",
    "        lookback,\n",
    "    )\n",
    "\n",
    "    plot_forecast(\n",
    "        ts[start_time:end_time],\n",
    "        grid,\n",
    "        spatial_traj[start_time:end_time],\n",
    "        fno_preds_spatial,\n",
    "        run_name=\"FNO\",\n",
    "        context_length=context_length,\n",
    "        save_path=os.path.join(figs_save_dir, \"ks_fno_spatial.pdf\"),\n",
    "        v_abs=our_spatial_vabs,\n",
    "        cmap_name=\"RdBu\",\n",
    "        title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 8},\n",
    "        show_ticks=False,\n",
    "        show_cbar=False,\n",
    "        figsize=(3, 5),\n",
    "        show_context=True,\n",
    "        draw_prediction_horizon_line=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_module(\"deepxde\"):\n",
    "    import deepxde as dde\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def deeponet_rollout(context: np.ndarray, num_steps: int, model: torch.nn.Module, xs: np.ndarray):\n",
    "        stand_context = safe_standardize(context, axis=0)\n",
    "        ic = torch.tensor(stand_context[-1]).float().to(device).unsqueeze(0)\n",
    "        traj = [ic]\n",
    "        state = ic.clone()\n",
    "        for _ in range(num_steps):\n",
    "            state = model((state, xs))\n",
    "            traj.append(state)\n",
    "        pred = torch.cat(traj, dim=0)[1:].cpu().numpy().squeeze()\n",
    "        traj = np.concatenate([stand_context, pred], axis=0)\n",
    "        return safe_standardize(traj, axis=0, context=context, denormalize=True)\n",
    "\n",
    "    hidden_dim = 256\n",
    "    n_layers = 6\n",
    "    net = dde.nn.DeepONetCartesianProd(\n",
    "        [ks.dimension] + n_layers * [hidden_dim],\n",
    "        [1] + n_layers * [hidden_dim],\n",
    "        \"tanh\",\n",
    "        \"He uniform\",\n",
    "    ).to(device)\n",
    "    state_dict = torch.load(\n",
    "        f\"{WORK_DIR}/checkpoints/KS-baselines-full/deeponet.pt\", map_location=device, weights_only=False\n",
    "    )[\"model_state_dict\"]\n",
    "    net.load_state_dict(state_dict)\n",
    "    net.eval()\n",
    "    torch.set_default_device(\"cpu\")\n",
    "\n",
    "    xs = np.linspace(0, ks.l, ks.dimension).astype(np.float32).reshape(-1, 1)  # (n,1)\n",
    "    xs = torch.from_numpy(xs).float().to(device)\n",
    "\n",
    "    don_preds_spatial = deeponet_rollout(\n",
    "        spatial_traj[start_time : start_time + context_length], end_time - start_time - context_length, net, xs\n",
    "    )\n",
    "\n",
    "    plot_forecast(\n",
    "        ts[start_time:end_time],\n",
    "        grid,\n",
    "        spatial_traj[start_time:end_time],\n",
    "        don_preds_spatial,\n",
    "        run_name=\"DeepONet\",\n",
    "        context_length=context_length,\n",
    "        save_path=os.path.join(figs_save_dir, \"ks_don_spatial.pdf\"),\n",
    "        v_abs=our_spatial_vabs,\n",
    "        cmap_name=\"RdBu\",\n",
    "        title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 8},\n",
    "        show_ticks=False,\n",
    "        show_cbar=False,\n",
    "        figsize=(3, 5),\n",
    "        show_context=True,\n",
    "        draw_prediction_horizon_line=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated for convenience\n",
    "start_time = 1024\n",
    "end_time = 2048\n",
    "context_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 40\n",
    "parent_rng = np.random.default_rng(12)\n",
    "rng_stream = parent_rng.spawn(n_runs)\n",
    "\n",
    "predict_spatial = True  # predict in spatial domain instead of frequency domain\n",
    "convert_to_spatial = False  # if prediction in freq domain, convert to spatial domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../outputs/kuramoto_sivashinsky\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_path = os.path.join(save_dir, f\"trajectories_{n_runs}.npy\")\n",
    "if os.path.exists(traj_path):\n",
    "    trajectories = np.load(traj_path, allow_pickle=True)\n",
    "else:\n",
    "    trajectories = []\n",
    "    for rng in rng_stream:\n",
    "        ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "        teval = np.linspace(0, tfinal, 4096)\n",
    "        sol = solve_ivp(ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8)\n",
    "        ts, freq_traj = sol.t, sol.y.T\n",
    "        if predict_spatial:\n",
    "            trajectories.append(ks.to_spatial(freq_traj, N=ks.dimension))\n",
    "        else:\n",
    "            trajectories.append(freq_traj)\n",
    "    np.save(traj_path, trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals = [(0, end) for end in np.arange(64, 512 + 64, 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_error(prediction, ground_truth, time_intervals: list[tuple[int, int]]):\n",
    "    pred_error_dict = {}\n",
    "    for start, end in time_intervals:\n",
    "        error_dict = compute_metrics(\n",
    "            prediction[start:end],\n",
    "            ground_truth[start:end],\n",
    "            include=[\"mae\", \"mse\", \"smape\"],\n",
    "        )\n",
    "        pred_error_dict[start, end] = error_dict\n",
    "    return pred_error_dict\n",
    "\n",
    "\n",
    "def get_mean_median_std_metrics_dicts_rollout(\n",
    "    predictions: list[np.ndarray],\n",
    "    trajectories: list[np.ndarray],\n",
    "    time_intervals: list[tuple[int, int]],\n",
    "):\n",
    "    pred_error_dict_lst = []\n",
    "    for preds, traj in zip(predictions, trajectories):\n",
    "        actual_preds = preds[context_length:]\n",
    "        actual_gt = traj[start_time:end_time][context_length:]\n",
    "        pred_error_dict_lst.append(compute_pred_error(actual_preds, actual_gt, time_intervals))\n",
    "\n",
    "    metrics_lst = [\"mse\", \"mae\", \"smape\"]\n",
    "    metric_dict = defaultdict(dict)\n",
    "    for time_interval in pred_error_dict_lst[0].keys():\n",
    "        for metric in metrics_lst:\n",
    "            values = []\n",
    "            for pred_error_dict in pred_error_dict_lst:\n",
    "                values.append(pred_error_dict[time_interval][metric])\n",
    "            values = np.array(values)\n",
    "            mean_metric = np.mean(values, axis=0)\n",
    "            median_metric = np.median(values, axis=0)\n",
    "            std_metric = np.std(values, axis=0)\n",
    "            metric_dict[time_interval][metric] = {\n",
    "                \"mean\": mean_metric,\n",
    "                \"median\": median_metric,\n",
    "                \"std\": std_metric,\n",
    "            }\n",
    "\n",
    "    mean_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            mean_metrics_dict[metric][time_interval] = metric_dict[time_interval][metric][\"mean\"]\n",
    "\n",
    "    median_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            median_metrics_dict[metric][time_interval] = metric_dict[time_interval][metric][\"median\"]\n",
    "\n",
    "    std_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            std_metrics_dict[metric][time_interval] = metric_dict[time_interval][metric][\"std\"]\n",
    "\n",
    "    return mean_metrics_dict, median_metrics_dict, std_metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_pred_path = os.path.join(save_dir, f\"{run_name}_preds_{n_runs}.npy\")\n",
    "if os.path.exists(panda_pred_path):\n",
    "    preds = np.load(panda_pred_path, allow_pickle=True)\n",
    "else:\n",
    "    preds = []\n",
    "    for traj in tqdm(trajectories):\n",
    "        sample_pred = forecast(\n",
    "            pipeline,\n",
    "            traj[start_time:end_time],\n",
    "            context_length,\n",
    "            prediction_length=None,\n",
    "            normalize=True,\n",
    "            sliding_context=True,\n",
    "        )\n",
    "        if convert_to_spatial and not predict_spatial:\n",
    "            sample_pred = ks.to_spatial(sample_pred, N=ks.dimension)\n",
    "        preds.append(sample_pred)\n",
    "    np.save(panda_pred_path, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_deterministic = True  # for Chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_pred_path = os.path.join(\n",
    "    save_dir,\n",
    "    f\"chronos_ft_preds_{n_runs}{'' if use_deterministic else '_nondeterministic'}.npy\",\n",
    ")\n",
    "if os.path.exists(chronos_ft_pred_path):\n",
    "    chronos_ft_preds = np.load(chronos_ft_pred_path, allow_pickle=True)\n",
    "else:\n",
    "    chronos_ft_preds = []\n",
    "\n",
    "    for traj in tqdm(trajectories):\n",
    "        chronos_ft_sample_pred = forecast_chronos(\n",
    "            chronos_ft,\n",
    "            traj[start_time:end_time],\n",
    "            context_length,\n",
    "            chunk_size=ks.dimension,\n",
    "            deterministic=use_deterministic,\n",
    "        )\n",
    "        if convert_to_spatial and not predict_spatial:\n",
    "            chronos_ft_sample_pred = ks.to_spatial(chronos_ft_sample_pred, N=ks.dimension)\n",
    "        chronos_ft_preds.append(chronos_ft_sample_pred)\n",
    "    np.save(chronos_ft_pred_path, chronos_ft_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_pred_path = os.path.join(\n",
    "    save_dir,\n",
    "    f\"chronos_zs_preds_{n_runs}{'' if use_deterministic else '_nondeterministic'}.npy\",\n",
    ")\n",
    "if os.path.exists(chronos_zs_pred_path):\n",
    "    chronos_zs_preds = np.load(chronos_zs_pred_path, allow_pickle=True)\n",
    "else:\n",
    "    chronos_zs_preds = []\n",
    "    for traj in tqdm(trajectories):\n",
    "        chronos_zs_sample_pred = forecast_chronos(\n",
    "            chronos_zs,\n",
    "            traj[start_time:end_time],\n",
    "            context_length,\n",
    "            chunk_size=ks.dimension,\n",
    "            deterministic=use_deterministic,\n",
    "        )\n",
    "        if convert_to_spatial and not predict_spatial:\n",
    "            chronos_zs_sample_pred = ks.to_spatial(chronos_zs_sample_pred, N=ks.dimension)\n",
    "        chronos_zs_preds.append(chronos_zs_sample_pred)\n",
    "    np.save(chronos_zs_pred_path, chronos_zs_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno_pred_path = os.path.join(save_dir, f\"fno_preds_{n_runs}.npy\")\n",
    "if has_module(\"neuralop\"):\n",
    "    if os.path.exists(fno_pred_path):\n",
    "        fno_preds = np.load(fno_pred_path, allow_pickle=True)\n",
    "    else:\n",
    "        fno_preds = []\n",
    "        for traj in tqdm(trajectories):\n",
    "            fno_sample_pred = fno_rollout(\n",
    "                traj[start_time : start_time + context_length],\n",
    "                end_time - start_time - context_length,\n",
    "                operator,\n",
    "                lookback=lookback,\n",
    "            )\n",
    "            fno_preds.append(fno_sample_pred)\n",
    "        np.save(fno_pred_path, fno_preds)\n",
    "else:\n",
    "    fno_preds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_pred_path = os.path.join(save_dir, f\"don_preds_{n_runs}.npy\")\n",
    "if has_module(\"deepxde\"):\n",
    "    if os.path.exists(don_pred_path):\n",
    "        don_preds = np.load(don_pred_path, allow_pickle=True)\n",
    "    else:\n",
    "        xs = np.linspace(0, ks.L, ks.dimension).astype(np.float32).reshape(-1, 1)  # (N,1)\n",
    "        xs = torch.from_numpy(xs).float().to(device)\n",
    "        don_preds = []\n",
    "        for traj in tqdm(trajectories):\n",
    "            don_sample_pred = deeponet_rollout(\n",
    "                traj[start_time : start_time + context_length], end_time - start_time - context_length, net, xs\n",
    "            )\n",
    "            don_preds.append(don_sample_pred)\n",
    "        np.save(don_pred_path, don_preds)\n",
    "else:\n",
    "    don_preds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [\"o\", \"s\", \"v\", \"^\", \"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_times = [end_time for _, end_time in time_intervals]\n",
    "for metric_to_plot, title_metric_name in [(\"smape\", \"sMAPE\")]:\n",
    "    fig = plt.figure(figsize=(4.5, 3.5))\n",
    "    for i, (run_name, plist) in enumerate(\n",
    "        zip(\n",
    "            [\"Panda\", \"Chronos 20M SFT\", \"Chronos 20M\", \"FNO\", \"DeepONet\"],\n",
    "            [preds, chronos_ft_preds, chronos_zs_preds, fno_preds, don_preds],\n",
    "        )\n",
    "    ):\n",
    "        if plist is None:\n",
    "            continue\n",
    "        mean_metrics_dict, median_metrics_dict, std_metrics_dict = get_mean_median_std_metrics_dicts_rollout(\n",
    "            plist, trajectories, time_intervals\n",
    "        )\n",
    "        mean_vals = np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "        std_vals = np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "        color = \"k\" if run_name in (\"FNO\", \"DeepONet\") else plt.gca()._get_lines.get_next_color()\n",
    "        plt.plot(\n",
    "            end_times,\n",
    "            list(mean_vals),\n",
    "            label=run_name,\n",
    "            marker=markers[i],\n",
    "            linestyle=\"-.\" if run_name in (\"FNO\", \"DeepONet\") else \"-\",\n",
    "            color=color,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            end_times,\n",
    "            np.array(list(mean_vals)) - np.array(list(std_vals)) / np.sqrt(len(time_intervals)),\n",
    "            np.array(list(mean_vals)) + np.array(list(std_vals)) / np.sqrt(len(time_intervals)),\n",
    "            alpha=0.2,\n",
    "            color=color,\n",
    "        )\n",
    "    plt.xticks(end_times)\n",
    "    plt.legend(loc=\"lower right\", frameon=True)\n",
    "    plt.title(\"Kuramoto Sivashinsky\", fontweight=\"bold\")\n",
    "    plt.ylabel(f\"{title_metric_name}\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(figs_save_dir, f\"ks_all_models_{metric_to_plot}.pdf\"),\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_times = [end_time for _, end_time in time_intervals]\n",
    "for metric_to_plot, title_metric_name in [(\"mae\", \"MAE\")]:\n",
    "    plt.figure(figsize=(4.5, 3.5))\n",
    "    for i, (run_name, plist) in enumerate(\n",
    "        zip(\n",
    "            [\"Panda\", \"Chronos 20M SFT\", \"Chronos 20M\", \"FNO\", \"DeepONet\"],\n",
    "            [preds, chronos_ft_preds, chronos_zs_preds, fno_preds, don_preds],\n",
    "        )\n",
    "    ):\n",
    "        if plist is None:\n",
    "            continue\n",
    "        mean_metrics_dict, median_metrics_dict, std_metrics_dict = get_mean_median_std_metrics_dicts_rollout(\n",
    "            plist, trajectories, time_intervals\n",
    "        )\n",
    "        mean_vals = np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "        std_vals = np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "        color = \"k\" if run_name in (\"FNO\", \"DeepONet\") else plt.gca()._get_lines.get_next_color()\n",
    "        plt.plot(\n",
    "            end_times,\n",
    "            list(mean_vals),\n",
    "            label=run_name,\n",
    "            marker=markers[i],\n",
    "            linestyle=\"-.\" if run_name in (\"FNO\", \"DeepONet\") else \"-\",\n",
    "            color=color,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            end_times,\n",
    "            np.array(list(mean_vals)) - np.array(list(std_vals)) / np.sqrt(len(time_intervals)),\n",
    "            np.array(list(mean_vals)) + np.array(list(std_vals)) / np.sqrt(len(time_intervals)),\n",
    "            alpha=0.1,\n",
    "            color=color,\n",
    "        )\n",
    "    plt.xticks(end_times)\n",
    "    plt.legend(loc=\"lower right\", frameon=True)\n",
    "    plt.title(\"Kuramoto Sivashinsky\", fontweight=\"bold\")\n",
    "    plt.ylabel(f\"{title_metric_name}\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "    plt.ticklabel_format(style=\"sci\", axis=\"y\", scilimits=(0, 0))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(figs_save_dir, f\"ks_all_models_{metric_to_plot}.pdf\"),\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
