{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7f27da",
   "metadata": {},
   "source": [
    "## Plot computed GP Dims\n",
    "\n",
    "See our script in `scripts/analysis/compute_gpdims.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8110a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from panda.utils.plot_utils import apply_custom_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_dir = os.path.join(\"../../figures\", \"eval_metrics_mlm\")\n",
    "os.makedirs(fig_save_dir, exist_ok=True)\n",
    "\n",
    "apply_custom_style(\"../../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.getenv(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")\n",
    "# eval_results_dir = os.path.join(WORK_DIR, \"eval_results_mlm\", \"panda\", \"panda_mlm-66M\", \"test_zeroshot\")\n",
    "eval_results_dir = os.path.join(WORK_DIR, \"eval_results_mlm\", \"panda_mlm\", \"panda_mlm-21M\", \"test_zeroshot\")\n",
    "data_split = \"test_zeroshot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_paths = {\n",
    "    # \"Panda MLM\": eval_results_dir,\n",
    "    # \"Polynomial Degree 3\": os.path.join(eval_results_dir, \"polynomial3\"),\n",
    "    \"Linear\": os.path.join(eval_results_dir, \"linear\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpdims_filepaths = {}\n",
    "for model_name, results_dict_path in results_dict_paths.items():\n",
    "    print(f\"Loading gpdim files for {model_name} from {results_dict_path}\")\n",
    "    gpdims_fnames = [f for f in os.listdir(results_dict_path) if f.endswith(\".json\") and \"gpdim\" in f]\n",
    "    print(f\"Found {len(gpdims_fnames)} gpdim files for {model_name}: {gpdims_fnames}\")\n",
    "    gpdims_filepaths[model_name] = [os.path.join(results_dict_path, f) for f in gpdims_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406050b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpdims_completions_all_runs = {}\n",
    "gpdims_groundtruth_all_runs = {}\n",
    "\n",
    "for model_name, gpdims_fnames in gpdims_filepaths.items():\n",
    "    print(f\"Processing {model_name} with {len(gpdims_fnames)} files\")\n",
    "    for gpdims_fname in gpdims_fnames:\n",
    "        # load gpdims\n",
    "        with open(gpdims_fname, \"r\") as f:\n",
    "            gp_dims = json.load(f)\n",
    "        print(f\"number of systems in {gpdims_fname}: {len(gp_dims)}\")\n",
    "        print(f\"gpdim of completions of first system in {gpdims_fname}: {gp_dims['LorenzStenflo_pp0']['completions']}\")\n",
    "        print(f\"gpdim of groundtruth of first system in {gpdims_fname}: {gp_dims['LorenzStenflo_pp0']['groundtruth']}\")\n",
    "        for sys_name, gp_dim_val in gp_dims.items():\n",
    "            if sys_name not in gpdims_completions_all_runs:\n",
    "                gpdims_completions_all_runs[sys_name] = []\n",
    "            gpdims_completions_all_runs[sys_name].append(gp_dim_val[\"completions\"])\n",
    "            if sys_name not in gpdims_groundtruth_all_runs:\n",
    "                gpdims_groundtruth_all_runs[sys_name] = []\n",
    "            gpdims_groundtruth_all_runs[sys_name].append(gp_dim_val[\"groundtruth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ee7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpdims_completions_all_runs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_system_name = next(iter(gpdims_completions_all_runs))\n",
    "print(test_system_name)\n",
    "test_gpdim_vals = gpdims_completions_all_runs[test_system_name]\n",
    "print(len(test_gpdim_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sys_name in gpdims_completions_all_runs.keys():\n",
    "    gpdims_completions_all_runs[sys_name] = np.mean(gpdims_completions_all_runs[sys_name])\n",
    "\n",
    "for sys_name in gpdims_groundtruth_all_runs.keys():\n",
    "    gpdims_groundtruth_all_runs[sys_name] = np.mean(gpdims_groundtruth_all_runs[sys_name])\n",
    "\n",
    "groundtruth_gp_dims = list(gpdims_groundtruth_all_runs.values())\n",
    "completions_gp_dims = list(gpdims_completions_all_runs.values())\n",
    "\n",
    "print(len(groundtruth_gp_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x = np.array(groundtruth_gp_dims)\n",
    "y = np.array(completions_gp_dims)\n",
    "\n",
    "# Remove outliers using z-score\n",
    "z_scores = np.abs(stats.zscore(np.vstack([x, y]).T, axis=0))\n",
    "outliers = np.any(z_scores > 3, axis=1)\n",
    "x_clean = x[~outliers]\n",
    "y_clean = y[~outliers]\n",
    "print(f\"Removed {np.sum(outliers)} outliers\")\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(x_clean.reshape(-1, 1), y_clean)\n",
    "slope, intercept = model.coef_[0], model.intercept_\n",
    "r_squared = model.score(x_clean.reshape(-1, 1), y_clean)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_clean, y_clean, color=\"black\", s=5, alpha=0.1)\n",
    "\n",
    "# Regression line\n",
    "line_x = np.linspace(min(x_clean), max(x_clean), 100)\n",
    "plt.plot(\n",
    "    line_x,\n",
    "    slope * line_x + intercept,\n",
    "    \"r-\",\n",
    "    alpha=0.9,\n",
    "    zorder=10,\n",
    "    label=f\"y = {slope:.2f}x + {intercept:.2f} (R² = {r_squared:.2f})\",\n",
    ")\n",
    "\n",
    "# Identity line\n",
    "bounds = [min(min(x_clean), min(y_clean)), max(max(x_clean), max(y_clean))]\n",
    "plt.plot(bounds, bounds, \"r--\", alpha=0.9, zorder=9, label=\"y = x\")\n",
    "\n",
    "plt.xlim(bounds)\n",
    "plt.ylim(bounds)\n",
    "plt.xlabel(\"Ground Truth\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Completions\", fontweight=\"bold\")\n",
    "plt.title(\"Correlation Dimension (Panda MLM-66M)\", fontweight=\"bold\", fontsize=10)\n",
    "plt.legend(loc=\"lower right\", frameon=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(\"../figures\", exist_ok=True)\n",
    "plt.savefig(\"../figures/gpdims.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# After you have x_clean and y_clean:\n",
    "\n",
    "# 1. Pearson Correlation Coefficient (measures linear correlation)\n",
    "pearson_r, pearson_p = stats.pearsonr(x_clean, y_clean)\n",
    "print(f\"Pearson r: {pearson_r:.3f} (p-value: {pearson_p:.3e})\")\n",
    "\n",
    "# 2. Spearman Correlation Coefficient (measures monotonic relationship, rank-based)\n",
    "spearman_rho, spearman_p = stats.spearmanr(x_clean, y_clean)\n",
    "print(f\"Spearman ρ: {spearman_rho:.3f} (p-value: {spearman_p:.3e})\")\n",
    "\n",
    "# 3. Mean Absolute Error (average absolute difference)\n",
    "mae = mean_absolute_error(x_clean, y_clean)\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "\n",
    "# 4. Root Mean Squared Error (penalizes larger errors more)\n",
    "rmse = np.sqrt(mean_squared_error(x_clean, y_clean))\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "\n",
    "# 5. Mean Absolute Percentage Error (relative error)\n",
    "mape = np.mean(np.abs((x_clean - y_clean) / x_clean)) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# 6. Concordance Correlation Coefficient (measures agreement, not just correlation)\n",
    "# This is particularly good for assessing agreement between measurements\n",
    "mean_x = np.mean(x_clean)\n",
    "mean_y = np.mean(y_clean)\n",
    "var_x = np.var(x_clean)\n",
    "var_y = np.var(y_clean)\n",
    "covariance = np.cov(x_clean, y_clean)[0, 1]\n",
    "ccc = (2 * covariance) / (var_x + var_y + (mean_x - mean_y) ** 2)\n",
    "print(f\"Concordance Correlation: {ccc:.3f}\")\n",
    "\n",
    "# 7. Kendall's Tau (another rank-based correlation)\n",
    "kendall_tau, kendall_p = stats.kendalltau(x_clean, y_clean)\n",
    "print(f\"Kendall's τ: {kendall_tau:.3f} (p-value: {kendall_p:.3e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370f092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
