{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from panda.utils.plot_utils import apply_custom_style\n",
    "\n",
    "apply_custom_style(\"../../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_dir = os.path.join(\"../../figures\", \"eval_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.getenv(\"WORK\", \"\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")\n",
    "ASSETS_DIR = os.path.join(\"../../assets\")\n",
    "eval_results_dir = os.path.join(WORK_DIR, \"eval_results_distributional_3200\")\n",
    "full_traj_lyap_r_fpath = os.path.join(ASSETS_DIR, \"max_lyap_r_test_zeroshot.json\")\n",
    "data_split = \"test_zeroshot\"\n",
    "run_name = \"lyap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Saved Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_chronos_deterministic = False\n",
    "chronos_dirname = \"chronos\" if use_chronos_deterministic else \"chronos_nondeterministic\"\n",
    "\n",
    "print(f\"Using {chronos_dirname} for chronos metrics\")\n",
    "\n",
    "\n",
    "def get_sorted_metric_fnames(save_dir):\n",
    "    def extract_window(fname):\n",
    "        m = re.search(r\"window-(\\d+)\", fname)\n",
    "        return int(m.group(1)) if m else float(\"inf\")\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        return []\n",
    "\n",
    "    return sorted(\n",
    "        [f for f in os.listdir(save_dir) if f.endswith(\".json\") and \"distributional_metrics\" in f], key=extract_window\n",
    "    )\n",
    "\n",
    "\n",
    "run_suffix = run_name if run_name else \"\"\n",
    "\n",
    "metrics_save_dirs = {\n",
    "    \"Panda\": os.path.join(eval_results_dir, \"panda\", \"panda-21M\", data_split, run_suffix),\n",
    "    \"Chronos 20M SFT\": os.path.join(eval_results_dir, chronos_dirname, \"chronos_t5_mini_ft-0\", data_split, run_suffix),\n",
    "    \"Chronos 20M\": os.path.join(eval_results_dir, chronos_dirname, \"chronos_mini_zeroshot\", data_split, run_suffix),\n",
    "    \"Chronos 200M\": os.path.join(eval_results_dir, chronos_dirname, \"chronos_base_zeroshot\", data_split, run_suffix),\n",
    "    \"Dynamix\": os.path.join(eval_results_dir, \"dynamix\", \"dynamix\", data_split, run_suffix),\n",
    "}\n",
    "model_run_names = list(metrics_save_dirs.keys())\n",
    "\n",
    "metrics_fnames = {}\n",
    "for model_name, save_dir in metrics_save_dirs.items():\n",
    "    print(f\"Loading {model_name} metrics from: {save_dir}\")\n",
    "    found_fnames = get_sorted_metric_fnames(save_dir)\n",
    "    metrics_fnames[model_name] = found_fnames\n",
    "    print(f\"Found {len(found_fnames)} {model_name} metrics files: {found_fnames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_none(values):\n",
    "    \"\"\"Remove None values from a list.\"\"\"\n",
    "    return [v for v in values if v is not None]\n",
    "\n",
    "\n",
    "def accumulate_metrics_lyap(metrics_fnames, metrics_save_dir):\n",
    "    max_lyap_accum = {\n",
    "        \"gt\": defaultdict(lambda: defaultdict(list)),\n",
    "        \"pred\": defaultdict(lambda: defaultdict(list)),\n",
    "        \"full_trajectory\": defaultdict(lambda: defaultdict(list)),\n",
    "    }\n",
    "    prediction_time_accum = defaultdict(list)\n",
    "\n",
    "    for fname in metrics_fnames:\n",
    "        with open(os.path.join(metrics_save_dir, fname), \"rb\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "        metrics = {int(k) if isinstance(k, str) else k: v for k, v in metrics.items()}\n",
    "\n",
    "        n_pred_intervals = len(metrics)\n",
    "        print(f\"number of prediction intervals in {fname}: {n_pred_intervals}\")\n",
    "        for pred_interval in metrics:\n",
    "            print(pred_interval)\n",
    "            data = metrics[pred_interval]\n",
    "            for system_name, system_entry in tqdm(data, desc=f\"Processing {pred_interval}\"):\n",
    "                max_lyap_accum[\"gt\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"prediction_horizon\"][\"max_lyap_gt\"]\n",
    "                )\n",
    "                max_lyap_accum[\"pred\"][pred_interval][system_name].append(\n",
    "                    system_entry[\"prediction_horizon\"][\"max_lyap_pred\"]\n",
    "                )\n",
    "                if \"full_trajectory\" in system_entry:\n",
    "                    max_lyap_accum[\"full_trajectory\"][pred_interval][system_name].append(\n",
    "                        system_entry[\"full_trajectory\"][\"max_lyap_full_traj\"]\n",
    "                    )\n",
    "                pred_time = system_entry[\"prediction_time\"]\n",
    "                prediction_time_accum[system_name].append(pred_time)\n",
    "\n",
    "    # Now, take the mean across all files for each metric, skipping None values\n",
    "    max_lyap = {k: defaultdict(dict) for k in max_lyap_accum.keys()}\n",
    "    prediction_time = {}\n",
    "\n",
    "    for key in [\"gt\", \"pred\", \"full_trajectory\"]:\n",
    "        for pred_interval in max_lyap_accum[key]:\n",
    "            for system_name, values in max_lyap_accum[key][pred_interval].items():\n",
    "                filtered = filter_none(values)\n",
    "                max_lyap[key][pred_interval][system_name] = float(np.mean(filtered)) if filtered else None\n",
    "                # max_lyap[key][pred_interval][system_name] = float(filtered[0]) if filtered else None\n",
    "\n",
    "    for system_name, times in prediction_time_accum.items():\n",
    "        times_arr = np.array(filter_none(times))\n",
    "        prediction_time[system_name] = np.mean(times_arr) if len(times_arr) > 0 else None\n",
    "\n",
    "    return {\n",
    "        \"max_lyap\": max_lyap,\n",
    "        \"prediction_time\": prediction_time,\n",
    "    }\n",
    "\n",
    "\n",
    "metrics_by_modelname = {}\n",
    "for model_name in metrics_save_dirs.keys():\n",
    "    print(f\"Accumulating {model_name} metrics...\")\n",
    "    metrics = accumulate_metrics_lyap(metrics_fnames[model_name], metrics_save_dirs[model_name])\n",
    "    metrics_by_modelname[model_name] = metrics\n",
    "    print(f\"Accumulated {model_name} metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    k: {m: metrics_by_modelname[m][k] for m in metrics_save_dirs.keys()} for k in [\"max_lyap\", \"prediction_time\"]\n",
    "}\n",
    "\n",
    "nan_masks = {\n",
    "    model_name: {pred_key: {} for pred_key in [\"gt\", \"pred\", \"full_trajectory\"]}\n",
    "    for model_name in metrics_save_dirs.keys()\n",
    "}\n",
    "\n",
    "# Remove None, NaN, and Inf values\n",
    "for model_name in metrics_save_dirs.keys():\n",
    "    for key in [\"gt\", \"pred\", \"full_trajectory\"]:\n",
    "        if key in metrics[\"max_lyap\"][model_name]:\n",
    "            for pred_interval in metrics[\"max_lyap\"][model_name][key]:\n",
    "                system_dict = metrics[\"max_lyap\"][model_name][key][pred_interval]\n",
    "                # Count and filter None, NaN, and Inf values\n",
    "                num_nones = sum(1 for v in system_dict.values() if v is None)\n",
    "                num_nans = sum(1 for v in system_dict.values() if v is not None and np.isnan(v))\n",
    "                num_infs = sum(1 for v in system_dict.values() if v is not None and np.isinf(v))\n",
    "                if num_nones > 0 or num_nans > 0 or num_infs > 0:\n",
    "                    print(\n",
    "                        f\"{model_name} - {key} - {pred_interval}: {num_nones} Nones, {num_nans} NaNs, {num_infs} Infs\"\n",
    "                    )\n",
    "                    nan_masks[model_name][key][pred_interval] = {\n",
    "                        s: v is not None and np.isfinite(v) for s, v in system_dict.items()\n",
    "                    }\n",
    "                else:\n",
    "                    nan_masks[model_name][key][pred_interval] = None\n",
    "                metrics[\"max_lyap\"][model_name][key][pred_interval] = {\n",
    "                    s: v for s, v in system_dict.items() if v is not None and np.isfinite(v)\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Lyapunov Exponent Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = 1024\n",
    "model_type = \"Panda\"\n",
    "use_full_traj_gt = False\n",
    "show_figure = True\n",
    "\n",
    "gt_key, gt_key_name = (\"full_trajectory\", \"Full Trajectory\") if use_full_traj_gt else (\"gt\", \"Ground Truth\")\n",
    "pred_key, pred_key_name = \"pred\", \"Prediction\"\n",
    "\n",
    "gt_dict = metrics[\"max_lyap\"][model_type][gt_key].get(pred_length, {})\n",
    "pred_dict = metrics[\"max_lyap\"][model_type][pred_key].get(pred_length, {})\n",
    "\n",
    "system_names = set(gt_dict) & set(pred_dict)\n",
    "x_raw = [gt_dict[s] for s in system_names]\n",
    "y_raw = [pred_dict[s] for s in system_names]\n",
    "\n",
    "# Filter out nan/inf\n",
    "x, y = [], []\n",
    "num_invalid = 0\n",
    "for xi, yi in zip(x_raw, y_raw):\n",
    "    if np.isfinite(xi) and np.isfinite(yi):\n",
    "        x.append(xi)\n",
    "        y.append(yi)\n",
    "    else:\n",
    "        num_invalid += 1\n",
    "\n",
    "r2 = r2_score(x, y) if x and y else float(\"nan\")\n",
    "print(f\"Filtered out {num_invalid} invalid (nan/inf) pairs from {len(x_raw)} total.\")\n",
    "print(f\"{model_type}: {pred_key_name} vs {gt_key_name} at L_pred={pred_length}, R^2={r2:.3f}\")\n",
    "\n",
    "if show_figure:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x, y, color=\"black\", s=5, alpha=0.1)\n",
    "    plt.xlabel(gt_key_name, fontweight=\"bold\")\n",
    "    plt.ylabel(pred_key_name, fontweight=\"bold\")\n",
    "    plt.title(rf\"{model_type} $\\lambda_{{\\max}}$ ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "\n",
    "    # y=x line\n",
    "    if x and y:\n",
    "        xy_min, xy_max = min(x + y), max(x + y)\n",
    "    else:\n",
    "        xy_min, xy_max = 0, 1\n",
    "    (h1,) = plt.plot([xy_min, xy_max], [xy_min, xy_max], \"r--\", label=r\"$y=x$\")\n",
    "\n",
    "    handles, labels = [], []\n",
    "    # Best fit line\n",
    "    if len(x) > 1 and len(y) > 1:\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        x_fit = np.array([xy_min, xy_max])\n",
    "        y_fit = m * x_fit + b\n",
    "        eqn_str = rf\"$y = {m:.2f}x$\" if abs(b) < 1e-10 else rf\"$y = {m:.2f}x {'+' if b >= 0 else '-'} {abs(b):.2f}$\"\n",
    "        eqn_r2_label = rf\"{eqn_str}  $(R^2 = {r2:.3f})$\" if not np.isnan(r2) else eqn_str\n",
    "        (h2,) = plt.plot(x_fit, y_fit, \"r-\", linewidth=1.5, label=eqn_r2_label)\n",
    "        handles += [h2, h1]\n",
    "        labels += [eqn_r2_label, r\"$y=x$\"]\n",
    "    else:\n",
    "        handles.append(h1)\n",
    "        labels.append(r\"$y=x$\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax.ticklabel_format(style=\"sci\", axis=\"both\", scilimits=(0, 0))\n",
    "    if handles:\n",
    "        ax.legend(handles=handles, labels=labels, loc=\"lower right\", fontsize=8, frameon=True)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\n",
    "    #     os.path.join(\n",
    "    #         fig_save_dir,\n",
    "    #         f\"max_lyap_r_full_pred_{pred_length}_{model_type}.pdf\",\n",
    "    #     ),\n",
    "    #     bbox_inches=\"tight\",\n",
    "    # )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in [\"Dynamix\", \"Panda\"]:\n",
    "    tmp = np.array(list(metrics[\"max_lyap\"][model_name][\"pred\"][3200].values()))\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  num nans in tmp: {np.sum(np.isnan(tmp))}\")\n",
    "    print(f\"  num infs in tmp: {np.sum(np.isinf(tmp))}\")\n",
    "    # total number of elements in tmp\n",
    "    print(f\"  total number of elements in tmp: {tmp.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = 3200\n",
    "use_full_traj_gt = False\n",
    "show_figure = True\n",
    "\n",
    "gt_key, gt_key_name = (\"full_trajectory\", \"Full Trajectory\") if use_full_traj_gt else (\"gt\", \"Ground Truth\")\n",
    "pred_key, pred_key_name = \"pred\", \"Prediction\"\n",
    "\n",
    "if show_figure:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Increase hatch linewidth so it appears in PDF\n",
    "plt.rcParams[\"hatch.linewidth\"] = 2.0\n",
    "\n",
    "model_types = list(metrics_by_modelname.keys())\n",
    "x_min = 0\n",
    "x_max = 8\n",
    "bins = np.linspace(x_min, x_max, 40)\n",
    "colors = DEFAULT_COLORS[:4] + [\"#FFB5B8\"]\n",
    "print(colors)\n",
    "\n",
    "gt_lyaps_to_plot = []  # this is simply because e.g. Dynamix has some nans, which we filter out, so we want to plot all the gt_lyaps\n",
    "for i, model_type in enumerate(model_types):\n",
    "    if model_type in [\"Chronos 20M SFT\", \"Chronos 20M\", \"Chronos 200M\"]:\n",
    "        continue\n",
    "    print(model_type)\n",
    "\n",
    "    if i == 0:\n",
    "        gt_dict = metrics[\"max_lyap\"][model_type][gt_key].get(pred_length, {})\n",
    "    pred_dict = metrics[\"max_lyap\"][model_type][pred_key].get(pred_length, {})\n",
    "    system_names = set(gt_dict) & set(pred_dict)\n",
    "\n",
    "    gt_lyaps = [gt_dict[s] for s in system_names]\n",
    "    if i == 0:\n",
    "        gt_lyaps_to_plot = gt_lyaps\n",
    "    pred_lyaps = [pred_dict[s] for s in system_names]\n",
    "\n",
    "    print(f\"{model_type}: {pred_key_name} vs {gt_key_name} at L_pred={pred_length}\")\n",
    "    print(f\"  {gt_key_name}: mean={np.mean(gt_lyaps):.3f}, std={np.std(gt_lyaps):.3f}\")\n",
    "    print(f\"  {pred_key_name}: mean={np.mean(pred_lyaps):.3f}, std={np.std(pred_lyaps):.3f}\")\n",
    "\n",
    "    if i == 4:\n",
    "        # For hatches to appear in PDF, we need to manually set the patches\n",
    "        n, bins_edges, patches = plt.hist(\n",
    "            pred_lyaps,\n",
    "            bins=bins,\n",
    "            color=colors[i],\n",
    "            alpha=0.6,\n",
    "            label=model_type,\n",
    "            density=False,\n",
    "            histtype=\"stepfilled\",\n",
    "            linewidth=2,\n",
    "            zorder=5 - i,\n",
    "            edgecolor=colors[i],\n",
    "        )\n",
    "        # Apply hatch to each patch with contrasting edge color\n",
    "        for patch in patches:\n",
    "            patch.set_hatch(\"////\")\n",
    "            patch.set_edgecolor(\"hotpink\")  # Use black for hatch visibility\n",
    "    else:\n",
    "        plt.hist(\n",
    "            pred_lyaps,\n",
    "            bins=bins,\n",
    "            color=colors[i],\n",
    "            alpha=0.6,\n",
    "            label=model_type,\n",
    "            density=False,\n",
    "            histtype=\"stepfilled\",\n",
    "            linewidth=2,\n",
    "            zorder=5 - i,\n",
    "        )\n",
    "\n",
    "# Plot ground truth histogram\n",
    "plt.hist(\n",
    "    gt_lyaps,\n",
    "    bins=bins,\n",
    "    color=\"black\",\n",
    "    alpha=0.8,\n",
    "    label=gt_key_name,\n",
    "    density=False,\n",
    "    linestyle=\"--\",\n",
    "    histtype=\"step\",\n",
    "    linewidth=2,\n",
    "    zorder=10,\n",
    ")\n",
    "\n",
    "plt.xlabel(r\"$\\lambda_{\\max}$\", fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "plt.title(rf\"$\\lambda_{{\\max}}$ Distribution ($L_{{\\mathrm{{pred}}}} = {pred_length}$)\", fontweight=\"bold\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.legend(loc=\"upper right\", fontsize=10, frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "save_path = os.path.join(fig_save_dir, f\"max_lyap_r_pred_{pred_length}_comparison.pdf\")\n",
    "print(f\"Saving to {save_path}\")\n",
    "plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Statistical Significance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Lyapunov of Full Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Rosenstein Lyapunov Exponents of the full trajectory\n",
    "full_traj_lyap_r_lst = json.load(open(full_traj_lyap_r_fpath))[\"4096\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_traj_lyap_r_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_traj_lyap_r_dict = {entry[0]: entry[1][\"max_lyap_rosenstein\"] for entry in full_traj_lyap_r_lst}\n",
    "print(len(full_traj_lyap_r_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make have same order of keys as metrics_by_modelname[\"Dynamix\"][\"max_lyap\"][\"pred\"][3200]\n",
    "full_traj_lyap_r_dict = {\n",
    "    k: full_traj_lyap_r_dict[k]\n",
    "    for k in metrics_by_modelname[\"Dynamix\"][\"max_lyap\"][\"pred\"][3200].keys()\n",
    "    if k in full_traj_lyap_r_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_traj_lyap_r_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_metrics_system_names = list(metrics_by_modelname[\"Dynamix\"][\"max_lyap\"][\"pred\"][3200].keys())\n",
    "# get overlap of keys\n",
    "overlap_keys = set(full_traj_lyap_r_dict.keys()) & set(example_metrics_system_names)\n",
    "print(len(overlap_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs. Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the prediction interval (pred_length) of 512\n",
    "pred_lengths = [3200]\n",
    "use_full_traj_gt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_full_traj_gt:\n",
    "    gt_key = \"full_trajectory\"\n",
    "    gt_key_name = \"Full Trajectory\"\n",
    "else:\n",
    "    gt_key = \"gt\"\n",
    "    gt_key_name = \"Ground Truth\"\n",
    "\n",
    "print(f\"(Prediction) vs {gt_key_name}\")\n",
    "\n",
    "for model_name in metrics_save_dirs.keys():\n",
    "    for pred_length in pred_lengths:\n",
    "        print(f\"Prediction Length L_pred = {pred_length}\")\n",
    "\n",
    "        gt_dict = metrics[\"max_lyap\"][model_name][gt_key].get(pred_length, {})\n",
    "        # gt_dict = full_traj_lyap_r_dict\n",
    "        pred_dict = metrics[\"max_lyap\"][model_name][pred_key].get(pred_length, {})\n",
    "\n",
    "        # Find the intersection of system names present in both\n",
    "        system_names = set(gt_dict.keys()) & set(pred_dict.keys())\n",
    "\n",
    "        # Prepare x and y data for scatter plot\n",
    "        x_raw = [gt_dict[sys] for sys in system_names]\n",
    "        y_raw = [pred_dict[sys] for sys in system_names]\n",
    "\n",
    "        # Filter out pairs where either value is nan or inf\n",
    "        x = []\n",
    "        y = []\n",
    "        num_invalid = 0\n",
    "        for xi, yi in zip(x_raw, y_raw):\n",
    "            # Convert to float if needed and check validity\n",
    "            try:\n",
    "                xi_float = float(xi) if not isinstance(xi, (int, float)) else xi\n",
    "                yi_float = float(yi) if not isinstance(yi, (int, float)) else yi\n",
    "                if (\n",
    "                    np.isfinite(xi_float)\n",
    "                    and np.isfinite(yi_float)\n",
    "                    and not np.isnan(xi_float)\n",
    "                    and not np.isnan(yi_float)\n",
    "                ):\n",
    "                    x.append(xi_float)\n",
    "                    y.append(yi_float)\n",
    "                else:\n",
    "                    num_invalid += 1\n",
    "            except (TypeError, ValueError):\n",
    "                num_invalid += 1\n",
    "\n",
    "        # Compute R^2 score\n",
    "        # NOTE: also can swap out with pearsonr here to compute pearson correlation\n",
    "        if len(x) > 0 and len(y) > 0:\n",
    "            r2 = r2_score(x, y)\n",
    "        else:\n",
    "            r2 = float(\"nan\")\n",
    "\n",
    "        # print(\n",
    "        #     f\"Filtered out {num_invalid} invalid (nan/inf) pairs from {len(x_raw)} total.\"\n",
    "        # )\n",
    "\n",
    "        print(f\"R^2={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "results = defaultdict(dict)\n",
    "for model_name in metrics_by_modelname.keys():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    lyaps_for_model = metrics_by_modelname[model_name][\"max_lyap\"][\"pred\"]\n",
    "    lyaps_for_gt = metrics_by_modelname[model_name][\"max_lyap\"][\"gt\"]\n",
    "    pred_lengths = list(lyaps_for_model.keys())\n",
    "    print(pred_lengths)\n",
    "    for pred_length in pred_lengths:\n",
    "        if pred_length == \"128\":  # TODO: remove when we have 128 predictions\n",
    "            continue\n",
    "        model_lyaps = [lyaps_for_model[pred_length][sys] for sys in lyaps_for_model[pred_length].keys()]\n",
    "        gt_lyaps = [lyaps_for_gt[pred_length][sys] for sys in lyaps_for_gt[pred_length].keys()]\n",
    "        nan_mask = nan_masks[model_name][\"pred\"][pred_length]\n",
    "        if nan_mask is not None:\n",
    "            print(f\"Masking gt_lyaps for {model_name} at pred_length {pred_length}\")\n",
    "            # nan_mask is a dict with system names as keys, not a list\n",
    "            # Filter gt_lyaps by matching system names\n",
    "            valid_systems = [sys for sys in lyaps_for_gt[pred_length].keys() if nan_mask.get(sys, False)]\n",
    "            gt_lyaps = [lyaps_for_gt[pred_length][sys] for sys in valid_systems]\n",
    "            print(f\"length of gt_lyaps: {len(gt_lyaps)}\")\n",
    "\n",
    "        # Convert to numpy arrays with explicit float dtype to avoid object dtype issues\n",
    "        gt_lyaps_array = np.array(gt_lyaps, dtype=np.float64)\n",
    "        model_lyaps_array = np.array(model_lyaps, dtype=np.float64)\n",
    "        # print number of nan values in gt_lyaps_array\n",
    "        print(\n",
    "            f\"number of nans in (gt, model): {np.sum(np.isnan(gt_lyaps_array))}, {np.sum(np.isnan(model_lyaps_array))}\"\n",
    "        )\n",
    "        print(f\"shapes of (gt_lyaps_array, model_lyaps_array): {gt_lyaps_array.shape}, {model_lyaps_array.shape}\")\n",
    "\n",
    "        # Filter out nan and inf values before computing metrics\n",
    "        valid_mask = np.isfinite(gt_lyaps_array) & np.isfinite(model_lyaps_array)\n",
    "        gt_lyaps_filtered = gt_lyaps_array[valid_mask]\n",
    "        model_lyaps_filtered = model_lyaps_array[valid_mask]\n",
    "\n",
    "        print(f\"Filtered to {len(gt_lyaps_filtered)} valid pairs from {len(gt_lyaps_array)} total\")\n",
    "\n",
    "        # measure correlation and wilcoxon signed rank test statistics and pvalues\n",
    "        if len(gt_lyaps_filtered) > 0:\n",
    "            pearson_result = pearsonr(gt_lyaps_filtered, model_lyaps_filtered)\n",
    "            r2_result = r2_score(gt_lyaps_filtered, model_lyaps_filtered)\n",
    "            print(f\"pearson_result: {pearson_result}\")\n",
    "            print(f\"r2_result: {r2_result}\")\n",
    "            results[model_name][pred_length] = {\n",
    "                \"pearson_corr\": float(f\"{pearson_result.statistic:.3f}\"),  # type: ignore\n",
    "                \"pearson_corr pval\": float(f\"{pearson_result.pvalue:.3e}\"),  # type: ignore\n",
    "                \"r2\": float(f\"{r2_result:.3f}\"),\n",
    "            }\n",
    "        else:\n",
    "            print(\"No valid pairs after filtering\")\n",
    "            results[model_name][pred_length] = {\n",
    "                \"pearson_corr\": float(\"nan\"),\n",
    "                \"pearson_corr pval\": float(\"nan\"),\n",
    "                \"r2\": float(\"nan\"),\n",
    "            }\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs. Full Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lyaps = [full_traj_lyap_r_dict[sys] for sys in full_traj_lyap_r_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_modelname[\"Dynamix\"][\"max_lyap\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# results = defaultdict(dict)\n",
    "# for model_name in metrics_by_modelname.keys():\n",
    "#     print(f\"Model: {model_name}\")\n",
    "#     lyaps_for_model = metrics_by_modelname[model_name][\"max_lyap\"][\"pred\"]\n",
    "#     for pred_length in lyaps_for_model.keys():\n",
    "#         if pred_length == \"128\":  # TODO: remove when we have 128 predictions\n",
    "#             continue\n",
    "#         model_lyaps = lyaps_for_model[pred_length]\n",
    "#         model_lyaps = [model_lyaps[sys] for sys in model_lyaps.keys()]\n",
    "#         if nan_masks[model_name][\"pred\"][pred_length] is not None:\n",
    "#             # mask full_lyaps with nan_masks[model_name][\"pred\"][pred_length]\n",
    "#             # full_lyaps is a list, but we need to filter by system names\n",
    "#             # Convert full_lyaps back to dict first\n",
    "#             full_lyaps_dict = {sys: full_traj_lyap_r_dict[sys] for sys in full_traj_lyap_r_dict.keys()}\n",
    "#             masked_full_lyaps = [full_lyaps_dict[sys] for sys in nan_masks[model_name][\"pred\"][pred_length].keys()]\n",
    "#         else:\n",
    "#             masked_full_lyaps = full_lyaps\n",
    "#         assert len(model_lyaps) == len(masked_full_lyaps), f\"{len(model_lyaps)} != {len(masked_full_lyaps)}\"\n",
    "\n",
    "#         # Convert to numpy arrays with explicit float dtype to avoid object dtype issues\n",
    "#         full_lyaps_array = np.array(masked_full_lyaps, dtype=np.float64)\n",
    "#         model_lyaps_array = np.array(model_lyaps, dtype=np.float64)\n",
    "\n",
    "#         # measure correlation and wilcoxon signed rank test statistics and pvalues\n",
    "#         result = pearsonr(full_lyaps_array, model_lyaps_array)\n",
    "#         results[model_name][pred_length] = {\n",
    "#             \"corr\": float(f\"{result.statistic:.3f}\"),  # type: ignore\n",
    "#             \"pval\": float(f\"{result.pvalue:.3e}\"),  # type: ignore\n",
    "#         }\n",
    "\n",
    "\n",
    "# pd.DataFrame(results).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
