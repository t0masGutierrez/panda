{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5051725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Iterator\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from neuralop import LpLoss\n",
    "from neuralop.models import FNO\n",
    "from neuralop.training import Trainer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from panda.utils.data_utils import safe_standardize\n",
    "from panda.utils.plot_utils import apply_custom_style\n",
    "\n",
    "apply_custom_style(\"../../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "re = 450\n",
    "fpath = f\"{base_dir}/von_karman_street/vortex_street_velocities_Re_{re}_4800timepoints.npz\"\n",
    "\n",
    "vfield = np.load(fpath, allow_pickle=True)\n",
    "vx = vfield[..., 0]\n",
    "vy = vfield[..., 1]\n",
    "dvx = np.gradient(vx, 2 / vx.shape[1], axis=2)\n",
    "dvy = np.gradient(vy, 1 / vy.shape[2], axis=1)\n",
    "vort_field = dvy + dvx\n",
    "vort_field_flattened = vort_field.reshape(vort_field.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 512\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(vort_field_flattened)\n",
    "X_ts = pca.transform(vort_field_flattened)  # (T, D)\n",
    "eigenvectors = pca.components_  # (D, H*W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(pca_coeffs: np.ndarray, eigenvectors: np.ndarray, modes: int = -1) -> np.ndarray:\n",
    "    if modes == -1:\n",
    "        modes = pca_coeffs.shape[1]\n",
    "    return pca_coeffs[:, :modes] @ eigenvectors[:modes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6beb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vort_recon = reconstruct(X_ts, eigenvectors)\n",
    "vort_recon = vort_recon.reshape(vort_field.shape[0], vort_field.shape[1], vort_field.shape[2])\n",
    "plt.figure()\n",
    "plt.imshow(vort_recon[100 + 512, :, :].T, cmap=\"seismic\")\n",
    "plt.colorbar(shrink=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = np.arange(0, 4096, 1024)\n",
    "n_runs = len(start_times)\n",
    "start_times = start_times.astype(int)\n",
    "print(f\"{len(start_times)} start_times: {start_times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a561521",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "context_length = 512\n",
    "prediction_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982de59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = np.stack([X_ts[start : start + context_length + prediction_length : stride] for start in start_times], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    trajs: torch.Tensor  # shape: (num_trajs, T, N)\n",
    "    context_length: int = 1\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.trajs.shape[0] * (self.trajs.shape[1] - self.context_length)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Iterator[tuple[torch.Tensor, torch.Tensor]]:\n",
    "        traj_idx = idx // (self.trajs.shape[1] - self.context_length)\n",
    "        i = idx % (self.trajs.shape[1] - self.context_length)\n",
    "        x = self.trajs[traj_idx, i : i + self.context_length]\n",
    "        y = self.trajs[traj_idx, i + self.context_length]\n",
    "        if y.ndim == 1:\n",
    "            y = y[np.newaxis, :]\n",
    "        if x.ndim == 1:\n",
    "            x = x[np.newaxis, :]\n",
    "        return {\n",
    "            \"x\": torch.from_numpy(x).float(),\n",
    "            \"y\": torch.from_numpy(y).float(),\n",
    "        }\n",
    "\n",
    "\n",
    "device_rank = 2\n",
    "device = f\"cuda:{device_rank}\"\n",
    "\n",
    "stand_trajs = safe_standardize(trajs, axis=1, context=trajs[:, :context_length])\n",
    "context_window = stand_trajs[:, :context_length]\n",
    "prediction_window = stand_trajs[:, context_length:]\n",
    "\n",
    "num_epochs = 5000\n",
    "batch_size = 512\n",
    "\n",
    "# preprocess training context\n",
    "lookback = 8\n",
    "train_dataset = Dataset(context_window, context_length=lookback)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(prediction_window, context_length=lookback),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "operator = FNO(n_modes=(512,), hidden_channels=256, n_layers=5, in_channels=lookback, out_channels=1).to(device)\n",
    "trainer = Trainer(model=operator, n_epochs=num_epochs, verbose=True, device=device)\n",
    "optimizer = torch.optim.AdamW(operator.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataset) * num_epochs)\n",
    "loss_fn = LpLoss(d=1)\n",
    "\n",
    "trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    test_loaders={\"eval\": test_loader},\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    training_loss=loss_fn,\n",
    "    save_every=1000,\n",
    "    save_dir=\"./vkvs_ckpt\",\n",
    "    save_best=\"eval_l2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbe778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(ic: torch.Tensor, num_steps: int, model: torch.nn.Module) -> torch.Tensor:\n",
    "    traj = [ic]\n",
    "    state = ic.clone()\n",
    "    for _ in range(num_steps):\n",
    "        pred = model(state)\n",
    "        traj.append(pred)\n",
    "        state = torch.cat([state[:, :-1, :], pred], dim=1)\n",
    "    return torch.cat(traj, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "WORK_DIR = os.path.expandvars(\"$WORK\")\n",
    "operator.load_state_dict(\n",
    "    # torch.load(f\"{WORK_DIR}/checkpoints/VKVS_baselines/best_model_state_dict.pt\", map_location=device, weights_only=False)\n",
    "    torch.load(\"vkvs_ckpt/best_model_state_dict.pt\", map_location=device, weights_only=False)\n",
    ")\n",
    "operator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e50956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediction\n",
    "prediction = (\n",
    "    rollout(\n",
    "        torch.from_numpy(context_window[0, -lookback:]).float().to(device).unsqueeze(0),\n",
    "        model=operator,\n",
    "        num_steps=prediction_length,\n",
    "    )\n",
    "    .squeeze()[lookback:]\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    ")\n",
    "prediction = safe_standardize(prediction, axis=0, context=trajs[0, :context_length], denormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db04430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_flow(\n",
    "    prediction: torch.Tensor,\n",
    "    trajectory: torch.Tensor,\n",
    "    eigenvectors: torch.Tensor,\n",
    "    num_modes: int,\n",
    "    shape: tuple[int, int] = (vort_field.shape[1], vort_field.shape[2]),\n",
    "    time_indices: list[int] | None = None,\n",
    "    save_path: str | None = None,\n",
    "    stride: int = 1,\n",
    "    cmap_name=\"seismic\",\n",
    "    base_figsize=(5, 5),\n",
    "    suptitle: str | None = None,\n",
    "    suptitle_y: float = 1.0,\n",
    "    **kwargs,\n",
    "):\n",
    "    recon = reconstruct(prediction[:, :num_modes], eigenvectors, modes=num_modes)\n",
    "    recon = recon.reshape(-1, shape[0], shape[1])\n",
    "    groundtruth = reconstruct(trajectory[:, :num_modes], eigenvectors, modes=num_modes)\n",
    "    groundtruth = groundtruth.reshape(-1, shape[0], shape[1])\n",
    "    vabs = max(np.abs(groundtruth.min()), np.abs(groundtruth.max()))\n",
    "\n",
    "    if time_indices is None:\n",
    "        time_indices = list(range(0, groundtruth.shape[0], stride))\n",
    "\n",
    "    aspect_ratio = shape[0] / shape[1]\n",
    "    fig = plt.figure(\n",
    "        figsize=(\n",
    "            base_figsize[0] * (len(time_indices)) / aspect_ratio,\n",
    "            base_figsize[1] * aspect_ratio,\n",
    "        )\n",
    "    )\n",
    "    gs = fig.add_gridspec(\n",
    "        2,\n",
    "        len(time_indices),\n",
    "        width_ratios=[1] * (len(time_indices)),\n",
    "        height_ratios=[1, 1],\n",
    "        wspace=0,\n",
    "        hspace=0,\n",
    "    )\n",
    "    axes = np.array([[fig.add_subplot(gs[i, j]) for j in range(len(time_indices))] for i in range(2)])\n",
    "    for i, index in enumerate(time_indices):\n",
    "        groundtruth_slice = groundtruth[index, :, :]\n",
    "        recon_slice = recon[index, :, :]\n",
    "\n",
    "        gax = axes[0, i].imshow(\n",
    "            groundtruth_slice,\n",
    "            vmin=-vabs,\n",
    "            vmax=vabs,\n",
    "            cmap=cmap_name,\n",
    "        )\n",
    "\n",
    "        axes[0, i].spines[\"top\"].set_visible(True)\n",
    "        axes[0, i].spines[\"right\"].set_visible(True)\n",
    "        axes[0, i].spines[\"bottom\"].set_visible(True)\n",
    "        axes[0, i].spines[\"left\"].set_visible(True)\n",
    "        axes[0, i].spines[\"top\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"right\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"bottom\"].set_color(\"black\")\n",
    "        axes[0, i].spines[\"left\"].set_color(\"black\")\n",
    "\n",
    "        axes[0, i].set_title(\n",
    "            \"t = context\" + (f\" + {index + 1}\" if index > 0 else \"\"),\n",
    "            fontsize=12,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "\n",
    "        rax = axes[1, i].imshow(\n",
    "            recon_slice,\n",
    "            vmin=-vabs,\n",
    "            vmax=vabs,\n",
    "            cmap=cmap_name,\n",
    "        )\n",
    "        axes[1, i].spines[\"top\"].set_visible(True)\n",
    "        axes[1, i].spines[\"right\"].set_visible(True)\n",
    "        axes[1, i].spines[\"bottom\"].set_visible(True)\n",
    "        axes[1, i].spines[\"left\"].set_visible(True)\n",
    "        axes[1, i].spines[\"top\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"right\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"bottom\"].set_color(\"black\")\n",
    "        axes[1, i].spines[\"left\"].set_color(\"black\")\n",
    "\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "\n",
    "        circle = plt.Circle((0.5 * shape[1] + 1, 0.145 * shape[0]), 5, fill=True, color=\"black\")\n",
    "        axes[0, i].add_patch(circle)\n",
    "        circle = plt.Circle((0.5 * shape[1] + 1, 0.145 * shape[0]), 5, fill=True, color=\"black\")\n",
    "        axes[1, i].add_patch(circle)\n",
    "\n",
    "    axes[0, 0].set_ylabel(\"Ground Truth\", fontweight=\"bold\", fontsize=16)\n",
    "    axes[1, 0].set_ylabel(\"Predictions\", fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "    if suptitle is not None:\n",
    "        plt.suptitle(suptitle, fontweight=\"bold\", fontsize=18, ha=\"center\", y=suptitle_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_flow(\n",
    "    prediction,\n",
    "    trajs[0, context_length:],\n",
    "    eigenvectors,\n",
    "    num_modes=n_components,\n",
    "    time_indices=[63, 127, 255, 383],\n",
    "    cmap_name=\"RdBu\",\n",
    "    camera_ready=False,\n",
    "    base_figsize=(4, 4),\n",
    "    suptitle=\"von Kármán Vortex Street\",\n",
    "    suptitle_y=0.98,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1d23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
